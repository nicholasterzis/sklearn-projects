{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6cdd1b-a7e8-4d03-8fff-da058813dbfc",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2499bc3b-5fa2-4c86-8a7a-3df466d57830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier, XGBRFClassifier \n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ed425-67bf-47e5-b654-15cea22c7741",
   "metadata": {},
   "source": [
    "## Set up Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b5d8c8d-c35f-45c1-8708-808dd01a462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CLASS  feature#1  feature#2  feature#3  feature#4  feature#5  feature#6  \\\n",
      "0      0     0.2482        0.0        0.0      1.337        0.0        0.0   \n",
      "1      0     0.0000        0.0        0.0      0.000        0.0        0.0   \n",
      "2      1     0.0000        0.0        0.0      0.000        0.0        0.0   \n",
      "3      0     0.0000        0.0        0.0      2.314        0.0        0.0   \n",
      "4      1     0.0000        0.0        0.0      0.000        0.0        0.0   \n",
      "\n",
      "   feature#7  feature#8  feature#9  ...  feature#4087  feature#4088  \\\n",
      "0        0.0        0.0        0.0  ...         1.152           0.0   \n",
      "1        0.0        0.0        0.0  ...         0.000           0.0   \n",
      "2        0.0        0.0        0.0  ...         0.000           0.0   \n",
      "3        0.0        0.0        0.0  ...         0.000           0.0   \n",
      "4        0.0        0.0        0.0  ...         0.000           0.0   \n",
      "\n",
      "   feature#4089  feature#4090  feature#4091  feature#4092  feature#4093  \\\n",
      "0         0.000           0.0          2.65           0.0           0.0   \n",
      "1         0.000           0.0          0.00           0.0           0.0   \n",
      "2         0.000           0.0          0.00           0.0           0.0   \n",
      "3         0.854           0.0          0.00           0.0           0.0   \n",
      "4         0.000           0.0          0.00           0.0           0.0   \n",
      "\n",
      "   feature#4094  feature#4095  feature#4096  \n",
      "0           0.0           0.0         0.000  \n",
      "1           0.0           0.0         4.297  \n",
      "2           0.0           0.0         3.773  \n",
      "3           0.0           0.0         3.277  \n",
      "4           0.0           0.0         2.832  \n",
      "\n",
      "[5 rows x 4097 columns]\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"train_set_ensembles.csv\").sample(frac=1).reset_index(drop=True)\n",
    "print(train_set.head())\n",
    "X = train_set.drop(columns=['CLASS'])\n",
    "y = train_set['CLASS'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a3dc4-31fe-46dc-936f-1ec4ba6a2638",
   "metadata": {},
   "source": [
    "## Voting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d9a4b1-6ea1-48b4-83d3-1b1e68a10ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1 = LogisticRegression(n_jobs = -1) # Classifier #1 \n",
    "cls2 = KNeighborsClassifier(n_jobs = -1) # Classifier #2 \n",
    "cls3 = DecisionTreeClassifier() # Classifier #3\n",
    "soft_vcls = VotingClassifier(estimators=[('lr', cls1), ('knn', cls2), ('dt', cls3)], voting='soft', n_jobs = -1) # Voting Classifier\n",
    "hard_vcls = VotingClassifier(estimators=[('lr', cls1), ('knn', cls2), ('dt', cls3)], voting='hard', n_jobs = -1) # Voting Classifier\n",
    "\n",
    "svlcs_scores = cross_validate(soft_vcls, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "s_avg_fmeasure = np.average(svlcs_scores['test_f1_weighted']) # The average f-measure\n",
    "s_avg_accuracy = np.average(svlcs_scores['test_accuracy']) # The average accuracy\n",
    "\n",
    "hvlcs_scores = cross_validate(hard_vcls, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "h_avg_fmeasure = np.average(hvlcs_scores['test_f1_weighted']) # The average f-measure\n",
    "h_avg_accuracy = np.average(hvlcs_scores['test_accuracy']) # The average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49354104-0cbb-4046-83c1-fc9d8af79b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\n",
      "VotingClassifier(estimators=[('lr', LogisticRegression(n_jobs=-1)),\n",
      "                             ('knn', KNeighborsClassifier(n_jobs=-1)),\n",
      "                             ('dt', DecisionTreeClassifier())],\n",
      "                 n_jobs=-1, voting='soft')\n",
      "F1 Weighted-Score: 0.8239 & Balanced Accuracy: 0.8244\n",
      "\n",
      "Classifier:\n",
      "VotingClassifier(estimators=[('lr', LogisticRegression(n_jobs=-1)),\n",
      "                             ('knn', KNeighborsClassifier(n_jobs=-1)),\n",
      "                             ('dt', DecisionTreeClassifier())],\n",
      "                 n_jobs=-1)\n",
      "F1 Weighted-Score: 0.8234 & Balanced Accuracy: 0.8239\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier:\")\n",
    "print(soft_vcls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(s_avg_fmeasure,4), round(s_avg_accuracy,4)))\n",
    "\n",
    "print(\"\\nClassifier:\")\n",
    "print(hard_vcls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(h_avg_fmeasure,4), round(h_avg_accuracy,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93325e65-8215-4cd2-95a5-7370e9e17495",
   "metadata": {},
   "source": [
    "## Stacking Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c26eb-8a75-44c3-a080-b46551ca26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1 = RandomForestClassifier(n_jobs = -1, n_estimators = 25) # Classifier #1 \n",
    "cls2 = GradientBoostingClassifier(n_estimators = 25) # Classifier #2 \n",
    "cls3 = LogisticRegression(n_jobs = -1) # Classifier #3\n",
    "cls4 = SVC()\n",
    "cls5 = MLPClassifier(hidden_layer_sizes = (25,))\n",
    "scls = StackingClassifier(estimators=[('svc', cls4), ('mlp', cls5)], final_estimator = cls3, n_jobs=-1, cv = 5) # Stacking Classifier\n",
    "\n",
    "scores = cross_validate(scls, X, y, cv=10, scoring = ('accuracy', 'f1_weighted')) \n",
    "avg_fmeasure = np.average(scores['test_f1_weighted']) # The average f-measure\n",
    "avg_accuracy = np.average(scores['test_accuracy']) # The average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df9514-d0f1-4a4a-bc8c-690a4502a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classifier:\")\n",
    "print(scls)\n",
    "print(\"F1 Weighted Score: {} & Balanced Accuracy: {}\".format(round(avg_fmeasure,4), round(avg_accuracy,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7105926-4331-42cc-bd0c-9cb2e64220e1",
   "metadata": {},
   "source": [
    "## Homogenous Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae32666-2bfd-419a-9ea1-841fec7845b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens1 = BaggingClassifier(n_estimators = 25, max_samples=0.4).fit(X, y) # Bagging with replacement by default (bootstrap)\n",
    "ens2 = BaggingClassifier(n_estimators = 25, max_features=0.4, bootstrap=False).fit(X, y) # Random Subspace without replacement by default (we have the default value for max_samples and we use bootstrap=False to get all of the samples once - just on a different order - so that we can see the effect of random subspace selection on its own without using different subsets of data ech time / getting random patches)\n",
    "ens3 = RandomForestClassifier(n_estimators = 25, n_jobs = -1) # Random Forest\n",
    "tree = DecisionTreeClassifier() # decision tree for comparison\n",
    "\n",
    "scores1 = cross_validate(ens1, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "scores2 = cross_validate(ens2, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "scores3 = cross_validate(ens3, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "scoresTree = cross_validate(tree, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "\n",
    "f_measures = dict(Bagging = np.average(scores1['test_f1_weighted']), RandomSubspace = np.average(scores2['test_f1_weighted']), RandomForest = np.average(scores3['test_f1_weighted']), Tree = np.average(scoresTree['test_f1_weighted']))\n",
    "accuracies = dict(Bagging = np.average(scores1['test_accuracy']), RandomSubspace = np.average(scores2['test_accuracy']), RandomForest = np.average(scores3['test_accuracy']), Tree = np.average(scoresTree['test_accuracy']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2943d-a877-46da-aa54-c38fd735875b",
   "metadata": {},
   "source": [
    "The three models used are:\n",
    "1. A bagging classifier using 0.4 of the available samples on 25 decision tree estimators to get a final result\n",
    "2. A random subspace classifier (bagging classifier) using 0.4 of the avalable features on 25 tree estimators to get a final result\n",
    "3. A Random Forest Classifier using 25 tree estimators to get a result\n",
    "4. A simple Decision Tree Estimator\n",
    "\n",
    "Initially when running tests with the default values the random forest algorithm did the best, something expected as it uses by default 100 estimators while the other methods use only 10. When using the same number of estimators however across the different methods we see that the random subspace algorithm seems to be giving us the best results followed by the bagging algorithm with random forest coming third. Of course as expected the simple decision tree falls short by a lot as it only effectively uses one estimator while the other algorithms use 25, each of them applied on different subsets of the data/features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d59408b-9774-487b-a0c9-fa803fb1d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Bagging -  F1 Weighted: 0.7958\n",
      "Classifier: RandomSubspace -  F1 Weighted: 0.8105\n",
      "Classifier: RandomForest -  F1 Weighted: 0.7855\n",
      "Classifier: Tree -  F1 Weighted: 0.7036\n",
      "Classifier: Bagging -  Balanced Accuracy: 0.7984\n",
      "Classifier: RandomSubspace -  Balanced Accuracy: 0.8129\n",
      "Classifier: RandomForest -  Balanced Accuracy: 0.7886\n",
      "Classifier: Tree -  Balanced Accuracy: 0.7033\n"
     ]
    }
   ],
   "source": [
    "for name,score in f_measures.items():\n",
    "    print(\"Classifier: {} -  F1 Weighted: {}\".format(name,round(score,4)))\n",
    "for name,score in accuracies.items():\n",
    "    print(\"Classifier: {} -  Balanced Accuracy: {}\".format(name,round(score,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b5be6-2fc8-4a1d-be57-96a954506720",
   "metadata": {},
   "source": [
    "## Testing Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182964ba-019f-4b66-829c-1c79b5052c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cls1 = GradientBoostingClassifier(n_estimators = 100)\n",
    "cls2 = XGBClassifier(n_estimators=100,tree_method='hist', subsample=0.5)\n",
    "#cls3 = XGBRFClassifier()\n",
    "#cls4 = AdaBoostClassifier(RandomForestClassifier(n_estimators=10), n_estimators=100)\n",
    "#cls5 = LogisticRegression(n_jobs = -1) # Classifier #3\n",
    "#cls6 = MLPClassifier(hidden_layer_sizes = (25,))\n",
    "cls7 = SVC()\n",
    "best_cls = StackingClassifier(estimators=[('xgb', cls2), ('svc', cls7)], final_estimator = cls3, n_jobs=-1, cv = 3)\n",
    "#cls8 = StackingClassifier(estimators=[('mlp', cls6), ('xgb', cls2)], final_estimator = cls3, n_jobs=-1, cv = 3)\n",
    "\n",
    "scores = cross_validate(cls7, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "#scores2 = cross_validate(cls2, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "#scores3 = cross_validate(cls3, X, y, cv=10, scoring = ('accuracy', 'f1_weighted'))\n",
    "\n",
    "best_fmeasure = np.average(scores['test_f1_weighted'])\n",
    "best_accuracy = np.average(scores['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5779fa2f-cecb-46ae-ab6b-4beac4dee4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\n",
      "F1 Weighted-Score:0.8601178182662387 & Balanced Accuracy:0.8608424366405274\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier:\")\n",
    "#print(best_cls)\n",
    "print(\"F1 Weighted-Score:{} & Balanced Accuracy:{}\".format(best_fmeasure, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ed361-be72-4eac-8a6a-e7555234447a",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### GradientBoosting\n",
    "f_measure: 0.8174, accuracy: 0.8191\n",
    "#### XGBClassifier (method = 'exact)\n",
    "f_measure: 0.8393, accuracy: 0.8403\n",
    "#### XGBClassifier (method = 'hist', also used subsample = o.5 to try a bagging method on every tree)\n",
    "f_measure: 0.8285, accuracy: 0.8296 (a bit worse than method='exact' but indeed much faster)\n",
    "#### XGBRFClasssifier (XBG Random Forest)\n",
    "f_measure: 0.7657, accuracy: 0.7719 (not much better than a simple random forest)\n",
    "#### AdaBoost + Random Forest\n",
    "f_measure: 0.8015, accuracy: 0.8084\n",
    "#### Stacking MLP + XGBClassifier(hist+subsample) combined with Logistic Regression:\n",
    "f_measure: 0.8572, accuracy: 0.8578 (better result but definitely not worth it over just XGB as it took almost an hour to compute)\n",
    "#### Stacking SVC + XGBClassifier(hist+subsample)\n",
    "f_measure: 0.8601, accuracy: 0.8608 (by far the most efficient option - time is almost the same as with XBG-hist alone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc60805-5c9b-477c-bc6b-265d0b5e2da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
